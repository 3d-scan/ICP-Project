\documentclass[a4paper]{article}
\usepackage{listings}
\usepackage{graphicx}
%\usepackage[scale=.7]{geometry}
\usepackage{amsmath}
\usepackage{float}
\usepackage{acronym}
\usepackage{cite}
\usepackage[usenames, pdftex]{color}

\acrodef{ICP}[ICP]{Iterated Closest Point}
\acrodef{RANSAC}[RANSAC]{Random Sample Consensus}
\acrodef{FPFH}[FPFH]{Fast Point Feature Histograms}

\title{Title\\
{\large Subtitle}}

\author{...\\
  University of Amsterdam\\
  The Netherlands}

\date{\today}




\begin{document}
\maketitle



\section{Introduction}

In this project we familiarized ourselves with several methods for 3D registration. The availability of cheap RGB+D sensors such as the Kinect could lead to new applications. A Kinect mounted on a moving robot could replace both it's RGB camera and it's range finder. A new application could be affordable 3D reconstructions of the insides of buildings. But in order to make sense of the Kinect's output, we need to perform a registration step; we need to \emph{register} the output of the RGB+D camera, i.e, we need to find the transformation that the camera made in between the captured frames. The robot's odometry can sometimes be used to get an initial estimate of the transformation, but in a scenario where the RGB+D camera is hand-held not even this is possible. For this reason we focused on the registration step only. 

The combined RGB and depth data forms a ``point cloud'', a set of 3D coordinate points indicating where the sensor measured a solid object. Assuming that there is enough overlap between each pair of consecutive point clouds, we find a good registration by finding an optimal way to fit the two clouds.


\section{Background}

\subsection{ICP Based Registration}

A basic method used in almost every approach to 3D registration is \ac{ICP}\cite{besl1992method}, it is an expectation maximization method that iteratively minimizes the distance between each point and it's closest neighbor. Though \ac{ICP} is currently used mostly as a refinement step for more advanced algorithms, there are still some papers describing experiments where using \ac{ICP} as the main registration procedure has been successful [[WHICH]]. 

In \cite{segal2009generalized}, an extension to \ac{ICP} was introduced that takes into account the local characteristics of the matched points. This Generalized-ICP gives a higher weight to point correspondence errors if they are in a direction perpendicular to the estimated plane. It is mentioned in both \cite{rusinkiewicz2001efficient} and \cite{segal2009generalized} that using this extension prevents the application of a closed-form solution to the minimization step.

Weighted scan matching removes a simplyfying assumption from ICP, namely that ``the range scans of different poses sample the environment's boundary at \emph{exactly} the same points''~\cite{pfister2002weighted}. This introduces an error which the authors name the \emph{correspondence error}. The correspondence error is the maximum distance between each point and it's closest match, which depends on the distance among the Model points, \cite{slamet2008boosting} give a clear illustration in their Figure 1. 

\subsection{Feature Based Registration}

An alternative to \ac{ICP} based registration is feature-based registration in which the transformation between frames is estimated from correspondences between feature points in 3D space, usually combined with \ac{RANSAC}. In stead of matching each point in the cloud to it's closest neighbour, characteristic points are extracted, and a feature \emph{descriptor} is calculated for each. Based on these descriptors, the feature points are matched to their counterparts in the other frame to get a number of \emph{correspondences}. Not all these correspondences may be correct though, so \ac{RANSAC} is often used to filter the outliers. \cite{rusu2009fast} describes such an approach using \ac{FPFH} with a variant of the \ac{ICP} algorithm as a refinement step. 

\section{Experiments}

We ran a number of experiments to find out about the behavior of different registration methods and their performance in different settings. One of the most influential properties of the input data is the magnitude of the transformation between frames. To clarify; a slow-driving robot will record frames that are are mostly similar, making it easier to find corresponding points or features in both frames, whereas a shaky handheld RGB-D camera might output frames with a much larger discrepancy. Typically, a set of frames with small transformations between them is an easier input to a registration algorithm. However, when building a global model or using the registration to perform SLAM, each step contributes an amount of error to the final results, therefore it is better to use as few frames as possible as long as the registration still works reasonably well. [[Is er een artikel waar ze frames overslaan onder bepaalde condities?: dat even citeren.]]

Our first experiment examines whether the total buildup of error is larger when using more frames, we did this by [[...]] We've also run the registration on the dataset to create a global model, to show that the buildup of error can be quite catastrophic for this purpose.

The rest of our experiments focus on the advantages of using feature-based registration methods when the magnitude of the relative transform between frames gets larger. All of these experiments consist of registering each frame $i$ to the $i-n^{\mathrm{th}}$ frame, with $n = 1,2,3,...$. By skipping frames in this manner, we artificially create a larger transformation for the registration step to solve. We expect to see that the feature-based methods are better at dealing with this larger transformation.

\subsection{Dataset}

As our dataset we chose an RGB-D dataset recorded by \cite{sturm11rss-rgbd}, in addition to the RGB-D feed, it contains a ground-truth for the camera's position, making it easier to evaluate our results. Moreover, this dataset was recorded with a relatively steady movement of the RGB-D sensor, so that the magnitude of the translation is constant.

\section{Results}

[[Grafiek die laat zien dat de error van A->B + B->C groter is dan van A->C, dat het dus zin heeft om frames te skippen]]

[[Grafiek die laat zien \emph{hoe groot} de transformaties zijn die ICP inschat, vergeleken bij de ground truth: misschien toont dat aan dat ICP altijd liever kleine transformaties kiest]]
[[In dezelfde grafiek: met een feature based methode]]

[[Grafiek met de gemiddelde relative error van ICP en van Feature-Based voor verschillende frameskips]]
[[Idem, voor andere dataset]]

[[Grafiek die laat zien dat ICP minder iteraties nodig heeft als er een Feature-Based stap aan vooraf gaat]]

\section{Discussion}

% Why does pure ICP work in the other articles? How do we show this?

% Why does ICP make SIFT results worse?

% Analysis of featurebased methods

% Why u no use color?


\bibliography{../../literature/refs}{}
\bibliographystyle{apalike}

\end{document}
